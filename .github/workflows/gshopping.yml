name: Google Shopping Scraper

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:  # Allow manual triggering
  push:
    branches: [ main, master ]
    paths:
      - 'gshopping/**'
      - '.github/workflows/shopping-scraper.yml'

jobs:
  scrape:
    runs-on: ubuntu-22.04  # Use Ubuntu 22.04 instead of latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
        
    - name: Install Chrome and dependencies
      run: |
        # Install Chrome from official Google repository
        sudo apt-get update
        sudo apt-get install -y \
          wget \
          curl \
          unzip \
          jq
        
        # Download and install Chrome
        wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt-get install -y ./google-chrome-stable_current_amd64.deb
        
        # Install minimal dependencies
        sudo apt-get install -y \
          libnss3 \
          libxss1 \
          libatk-bridge2.0-0 \
          libgtk-3-0 \
          libgbm1 \
          libx11-xcb1 \
          libxcomposite1 \
          libxdamage1 \
          libxrandr2 \
          libasound2t64 \
          libpangocairo-1.0-0
        
        # Verify Chrome installation
        echo "Chrome version:"
        google-chrome --version
        
    - name: Install ChromeDriver using webdriver-manager
      run: |
        # Install Python packages first
        pip install webdriver-manager==4.0.1
        
        # Test webdriver-manager
        python -c "from webdriver_manager.chrome import ChromeDriverManager; print('WebDriver Manager imported successfully')"
        
    - name: Install Python dependencies
      run: |
        cd gshopping
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create configuration files
      run: |
        cd gshopping
        
        # Create product_urls.json if it doesn't exist
        if [ ! -f "product_urls.json" ]; then
          cat > product_urls.json << 'EOF'
          [
            {
              "product_id": 1,
              "url": "https://www.google.com/search?q=office+chair&tbm=shop&gl=US&hl=en",
              "keyword": "office chair",
              "test": true
            },
            {
              "product_id": 2,
              "url": "https://www.google.com/search?q=wireless+headphones&tbm=shop&gl=US&hl=en",
              "keyword": "wireless headphones",
              "test": true
            }
          ]
          EOF
          echo "Created sample product_urls.json"
        fi
        
        # Create requirements.txt if it doesn't exist
        if [ ! -f "requirements.txt" ]; then
          cat > requirements.txt << 'EOF'
          # Core dependencies
          selenium==4.15.0
          webdriver-manager==4.0.1
          beautifulsoup4==4.12.2
          requests==2.31.0
          lxml==4.9.3
          
          # Data processing
          pandas==2.0.3
          numpy==1.24.3
          
          # Utilities
          fake-useragent==1.4.0
          python-dateutil==2.8.2
          python-dotenv==1.0.0
          
          # Output
          openpyxl==3.1.2
          xlsxwriter==3.1.9
          EOF
          echo "Created requirements.txt"
        fi
        
    - name: Run Google Shopping Scraper
      run: |
        cd gshopping
        echo "Starting scraper..."
        python gscrapperci.py
        
    - name: Display results
      run: |
        cd gshopping
        echo "=== Scraping Results ==="
        
        if [ -d "scraping_results" ]; then
          echo "Directory contents:"
          ls -la scraping_results/
          
          # Show summary if exists
          if [ -f "scraping_results/summary.json" ]; then
            echo -e "\n=== Summary ==="
            echo "Total products: $(jq '.metadata.total_products // 0' scraping_results/summary.json 2>/dev/null || echo '0')"
            echo "Successful: $(jq '.products | map(select(.status | test("found|success|container|completed"))) | length' scraping_results/summary.json 2>/dev/null || echo '0')"
          fi
        else
          echo "No results directory found"
        fi
        
    - name: Upload results as artifact
      uses: actions/upload-artifact@v4
      with:
        name: google-shopping-results
        path: |
          gshopping/scraping_results/
          gshopping/*.log
        retention-days: 30
        if-no-files-found: warn
        
    - name: Create workflow summary
      if: always()
      run: |
        echo "## Google Shopping Scraper Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run ID:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
        echo "**Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Time:** $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        cd gshopping
        
        if [ -d "scraping_results" ]; then
          echo "### ✅ Results Generated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count files
          CSV_COUNT=$(find scraping_results -name "*.csv" -type f | wc -l)
          JSON_COUNT=$(find scraping_results -name "*.json" -type f | wc -l)
          
          echo "- CSV Files: $CSV_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- JSON Files: $JSON_COUNT" >> $GITHUB_STEP_SUMMARY
          
          # Show sample if available
          if [ -f "scraping_results/all_products.csv" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Sample Data" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`csv" >> $GITHUB_STEP_SUMMARY
            head -3 scraping_results/all_products.csv | head -5 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "### ❌ No Results Generated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the logs for errors." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Results available as artifacts*" >> $GITHUB_STEP_SUMMARY